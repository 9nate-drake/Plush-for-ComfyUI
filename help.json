{
    "sp_help": "\u2022  This node's name is 'Enhancer' in the double click node 'Search' dialogue for ComfyUI. \n\n\u2022  Use 'Show Text|pysssss' nodes for displaying text output from Plush nodes.  Plush outputs text as UTF-8 Unicode, which Show Text can display correctly.\n\n\n****************\n\n\n\u2726 GPTmodel: Select the ChatGPT model you want to use to generate the prompt.  'gpt-4'1106-preview' is the new turbo gpt-4.\n\n\u2726 creative_latitude:  Higher numbers give the model more freedom to interpret your prompt or image.  Lower numbers constrain the model to stick closely to your input.\n\n\u2726 tokens: A limit on how many tokens are made available for ChatGPT to use, it doesn't have to use them all.\n\n\u2726 style: Choose the art style you want to base your prompt on.  If this list is too long, type a few characters of the style you're looking for and the list will dynamically filter.\n\n\u2726 artist: Will produce a 'style of' phrase listing the number of artists you indicate.  They will be artists that work in the chosen style.  Choose 0 if you don't want this.\n\n\u2726 prompt_style: 'Narrative' is long form grammatically correct creative writing, This is the preferred form for Dall-e. 'Tags' is a terse, stripped down list of visual attributes without grammatical phrasing, This is the preferred form for SD and Midjourney.\n\n\u2726 max_elements: A limit on the number of distinct descriptions of visual elements in the prompt. Smaller numbers makes a shorter prompt.\n\n\u2726 style_info: Set to True if you want background information about the art style you chose.",
    "wrangler_help": "\u2022  Use 'Show Text|pysssss' nodes for displaying text output from Plush nodes.  Plush outputs text as UTF-8 Unicode, which Show Text can display correctly.\n\n\u2022 Exif Wrangler will extract Exif and/or AI generation workflow metadata from .jpg (.jpeg) and .png images.  .jpg photographs can be queried for their camera settings.  ComfyUI's .png files will yield certain values from their workflow including the prompt, seed etc.  Images from other AI generators may or may not yield data depending on where they store their metadata. For instance Auto 1111 .jpg's will yield their workflow information that's stored in their Exif comment.\n\n**************\n  \n\u2726 write_to_file: Whether or not to save the meta data file you see in the output to a .txt file in the: '.../ComfyUI/output/PlushFiles' directory.\n\n\u2726 file_prefix: The prefix for the file name of the saved file, this will be appended to a date/time value to make the file unique. The file will have a .txt extension: e.g., 'MyFileName_ew_20240204_193224.txt'\n\n\u2726 Min_Prompt_len:  A filter value for prompts: Exif Wrangler has to distinguish between actual prompts and other long strings in the ComfyUI embeded meta data.  Every Note, every text display box, and even some text that's hidden in nodes is included in the JSON that holds this information.  This field allows you to set a minimum length for strings to be displayed to help filter out shorter unwanted text strings.\n\n\u2726 Alpha_Char_Pct: Another prompt filter that works by only allowing text strings that have a percentage of alpha ASCII characters (Aa - Zz plus comma) equal to or higher than this setting.  Increasing the percentage screens out strings that have lots of bytes, symbols and numbers.  If you use a lot of weightings or Lora values in your prompts that introduce angle brackets, parentheses, brackets and colons, you may have to lower this percentage to see your prompt.  \n\n\u2726 Prompt_Filter_Term:  Enter a single term or short phrase here. A particular prompt string will only be included in Possible Prompts if it contains an exact match for this term.  This can be used in a couple of ways:  \n 1) If you know there's a term you always or frequently use in the prompts, or if you remember part of a particular image prompt's wording,  you can add it here before you click the Queue button.  \n 2) If, after clicking Queue, a lot of Possible Prompt candidates clutter your output.  Find the one you know is the actual prompt, find a unique word or phrase in it e.g.: 'regal'.  Enter that word or phrase as a filter term and run Wrangler again.  You'll get back an uncluttered response to save as a file.\n\n***************\n\n\u2726 troubleshooting output:  Hook this output up to a text display node to see any INFO/WARNING/ERROR data that's generated during this node's run. ",
	"dalle_help": "\u2022  Use 'Show Text|pysssss' nodes for displaying text output from Plush nodes.  Plush outputs text as UTF-8 Unicode, which Show Text can display correctly.\n\n\u2022 Dall-e Image will produce an image .PNG from a text prompt using the Dall-e 3 model from OpenAI. It requires a OpenAI API key.\n\n**************\n\n\u2726 GPTmodel: The Dall-e model that will generate the image file.  Currently this is limited to Dall-e 3.\n\n\u2726 prompt: The text prompt for the image you want to produce.  Be aware that OpenAI will generate their own prompt from your prompt and pass that to the image model.\n\n\u2726 image_size: Choose a square, portrait or landscape image.  The image size format is: Width, Height.  The 1792 image sizes cost slightly more tokens.\n\n\u2726 image_quality: Self explanatory, you can experiment to see if you think there's a noticable difference.  The standard quality image costs a few less tokens than hd.\n\n\u2726 style: Vivid produces a little more contrast and more saturated colors.  The choice depends on what type of image you're trying to produce.\n\n\u2726  batch_size:  The number of images you want to produce in one run.  The vast majority of the times batches run without incident, but you should be aware that sending image requests to the Dall-e server is not as reliable as running images locally in SD.  If the server gets overtaxed, or hiccups you may not get back all the images you requested. This Dall-e node will handle OpenAI server errors gracefully and allow your batch to continue to completion, but sometimes you may get back fewer images than you requested.  If you keep the 'troubleshooting' output connected it will report any errors and let you know how many images were processed vs how many you requested.\n\n\u2726  seed:  This works just like a seed in a KSampler except that it doesn't affect a latent or the image.  It's simply there for you to set to: 'randomize' or 'increment' if you want Dall-e to run with every Queue, or to 'fixed' if you only want Dall-e to run once per prompt or setting.  The Dall_e API doesn't actually pass seed values.  This can also be controlled by the 'Global Seed' from the Inspire Pack. \n\n***************\n\n\u2726 troubleshooting output:  Hook this output up to a text display node to see any INFO/WARNING/ERROR data that's generated during this node's run.\n\n\u2726  Dalle_e_prompt: The prompt that Dall-e 3 generates from your prompt.  This is the prompt that actually gets passed to the image model.  Hook up a text display node to see it."
}